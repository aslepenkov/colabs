{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdioJp-GwEP9"
      },
      "outputs": [],
      "source": [
        "!pip install -q TTS langid unidic-lite unidic deepspeed gtts moviepy Pillow\n",
        "!pip install -q numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-z72o2xFMXm"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def parse_quiz_file(file_path):\n",
        "    # Read the file content\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = [line.strip() for line in file if line.strip()]\n",
        "\n",
        "    # Initialize the structure\n",
        "    quizzes = {\"quizzes\": []}\n",
        "    quiz_batch = []\n",
        "\n",
        "    # Iterate through the lines, assuming alternating question-answer pairs\n",
        "    for i in range(0, len(lines), 2):  # Step by 2 to get question-answer pairs\n",
        "        question = lines[i]\n",
        "        answer = lines[i + 1] if i + 1 < len(lines) else \"\"\n",
        "        quiz_batch.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "        # Every time we get 5 questions, add them as a quiz object and reset\n",
        "        if len(quiz_batch) == 5:\n",
        "            quizzes[\"quizzes\"].append({\"questions\": quiz_batch})\n",
        "            quiz_batch = []\n",
        "\n",
        "    # Add any remaining questions (if there are fewer than 5 in the last batch)\n",
        "    if quiz_batch:\n",
        "        quizzes[\"quizzes\"].append({\"questions\": quiz_batch})\n",
        "\n",
        "    return quizzes\n",
        "\n",
        "# Specify the file path of your text file\n",
        "file_path = 'quiz.txt'\n",
        "\n",
        "# Parse the file and get the result in desired structure\n",
        "quiz_structure = parse_quiz_file(file_path)\n",
        "\n",
        "# Print the result in a pretty JSON format\n",
        "print(json.dumps(quiz_structure, indent=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kygwdS_-FphB"
      },
      "outputs": [],
      "source": [
        "# prompt: get all files in /content/output folder and zip em!\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "def zipdir(path, ziph):\n",
        "    # ziph is zipfile handle\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            ziph.write(os.path.join(root, file))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    zipf = zipfile.ZipFile('/content/output.zip', 'w', zipfile.ZIP_DEFLATED)\n",
        "    zipdir('/content/output', zipf)\n",
        "    zipf.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3ZrFhYshdhc",
        "outputId": "0f2733ec-08da-4035-96cb-1a0b03288997"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import torch\n",
        "import torchaudio\n",
        "from gtts import gTTS\n",
        "from moviepy.editor import AudioFileClip, ImageClip, concatenate_videoclips, CompositeAudioClip\n",
        "from PIL import Image, ImageDraw, ImageFont, ImageFilter\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "from TTS.utils.manage import ModelManager\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "# Download for mecab\n",
        "os.system('python -m unidic download')\n",
        "\n",
        "# By using XTTS you agree to CPML license https://coqui.ai/cpml\n",
        "os.environ[\"COQUI_TOS_AGREED\"] = \"1\"\n",
        "\n",
        "# Initialize and download the XTTS model\n",
        "def initialize_xtts_model():\n",
        "    print(\"Downloading Coqui XTTS V2 if not already downloaded\")\n",
        "    model_name = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
        "    ModelManager().download_model(model_name)\n",
        "    model_path = \"/root/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2\"\n",
        "    print(\"XTTS downloaded\")\n",
        "\n",
        "    config = XttsConfig()\n",
        "    config.load_json(os.path.join(model_path, \"config.json\"))\n",
        "\n",
        "    model = Xtts.init_from_config(config)\n",
        "    model.load_checkpoint(\n",
        "        config,\n",
        "        checkpoint_path=os.path.join(model_path, \"model.pth\"),\n",
        "        vocab_path=os.path.join(model_path, \"vocab.json\"),\n",
        "        speaker_file_path=os.path.join(model_path, \"speakers_xtts.pth\"),\n",
        "        eval=True,\n",
        "        use_deepspeed=True,\n",
        "    )\n",
        "    model.cuda()\n",
        "    return model\n",
        "\n",
        "model = initialize_xtts_model()\n",
        "\n",
        "# Get conditioning latents\n",
        "def get_conditioning_latents(model, speaker_wav):\n",
        "    try:\n",
        "        return model.get_conditioning_latents(\n",
        "            audio_path=speaker_wav, gpt_cond_len=30, gpt_cond_chunk_len=4, max_ref_length=60\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Speaker encoding error: {str(e)}\")\n",
        "        print(\"It appears something is wrong with the reference. Did you unmute your microphone?\")\n",
        "        return None, None\n",
        "\n",
        "speaker_wav = \"/content/hermione.mp3\"\n",
        "gpt_cond_latent, speaker_embedding = get_conditioning_latents(model, speaker_wav)\n",
        "\n",
        "# Load quiz from JSON\n",
        "def load_quiz(quiz_file):\n",
        "    with open(quiz_file, 'r', encoding='utf-8') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "# Create blurred wrapped text image\n",
        "def create_blurred_wrapped_text_image(font, text, background_image_path, width=1080, height=1920, text_color=\"black\", blur_radius=15, box_opacity=150):\n",
        "    background = Image.open(background_image_path).resize((width, height))\n",
        "    blurred_background = background.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
        "    overlay = Image.new('RGBA', (width, height), (255, 255, 255, 0))\n",
        "    draw_overlay = ImageDraw.Draw(overlay)\n",
        "\n",
        "    def wrap_text(draw, text, font, max_width):\n",
        "        lines = []\n",
        "        words = text.split()\n",
        "        current_line = \"\"\n",
        "\n",
        "        for word in words:\n",
        "            test_line = f\"{current_line} {word}\".strip()\n",
        "            if draw.textbbox((0, 0), test_line, font=font)[2] <= max_width:\n",
        "                current_line = test_line\n",
        "            else:\n",
        "                lines.append(current_line)\n",
        "                current_line = word\n",
        "\n",
        "        if current_line:\n",
        "            lines.append(current_line)\n",
        "\n",
        "        return lines\n",
        "\n",
        "    wrapped_lines = wrap_text(draw_overlay, text, font, width - 40)\n",
        "    total_text_height = sum(draw_overlay.textbbox((0, 0), line, font=font)[3] - draw_overlay.textbbox((0, 0), line, font=font)[1] for line in wrapped_lines)\n",
        "    start_y = (height - total_text_height) // 2\n",
        "\n",
        "    box_padding = 20\n",
        "    for line in wrapped_lines:\n",
        "        line_bbox = draw_overlay.textbbox((0, 0), line, font=font)\n",
        "        line_x = (width - (line_bbox[2] - line_bbox[0])) // 2\n",
        "        box_coords = (line_x - box_padding, start_y, line_x + (line_bbox[2] - line_bbox[0]) + box_padding, start_y + (line_bbox[3] - line_bbox[1]) + box_padding)\n",
        "        draw_overlay.rectangle(box_coords, fill=(255, 255, 255, box_opacity))\n",
        "        draw_overlay.text((line_x, start_y), line, fill=text_color, font=font)\n",
        "        start_y += line_bbox[3] - line_bbox[1]\n",
        "\n",
        "    combined = Image.alpha_composite(blurred_background.convert('RGBA'), overlay)\n",
        "    temp_image = \"temp_blurred_text_image_fixed.png\"\n",
        "    combined.save(temp_image)\n",
        "\n",
        "    return temp_image\n",
        "\n",
        "# Generate text-to-speech (TTS) audio\n",
        "def generate_tts(text, language='en', filename=\"tts_audio.mp3\"):\n",
        "    tts = gTTS(text=text, lang=language)\n",
        "    tts.save(filename)\n",
        "    return AudioFileClip(filename)\n",
        "\n",
        "def generate_xttsv2(text, model, gpt_cond_latent, speaker_embedding, language='en', filename=\"tts_audio.mp3\"):\n",
        "    prompt = re.sub(\"([^\\x00-\\x7F]|\\w)(\\.|\\ã€‚|\\?)\", r\"\\1 \\2\\2\", text)\n",
        "    print(\"I: Generating new audio...\")\n",
        "    t0 = time.time()\n",
        "    out = model.inference(\n",
        "        prompt,\n",
        "        language,\n",
        "        gpt_cond_latent,\n",
        "        speaker_embedding,\n",
        "        repetition_penalty=5.0,\n",
        "        temperature=0.75,\n",
        "    )\n",
        "    inference_time = time.time() - t0\n",
        "    print(f\"I: Time to generate audio: {round(inference_time*1000)} milliseconds\")\n",
        "    real_time_factor = (time.time() - t0) / out['wav'].shape[-1] * 24000\n",
        "    print(f\"Real-time factor (RTF): {real_time_factor}\")\n",
        "    torchaudio.save(\"/content/output.wav\", torch.tensor(out[\"wav\"]).unsqueeze(0), 24000)\n",
        "    return AudioFileClip(\"/content/output.wav\")\n",
        "\n",
        "# Generate video for quiz\n",
        "def create_quiz_video(quiz, quiz_data, output_file, model, gpt_cond_latent, speaker_embedding):\n",
        "    clips = []\n",
        "    music_clip = AudioFileClip(quiz_data['background_music']).volumex(0.2)\n",
        "    font = ImageFont.truetype(quiz_data['font'], 80)\n",
        "\n",
        "    for item in quiz[\"questions\"]:\n",
        "        question = item['question']\n",
        "        answer = item['answer']\n",
        "\n",
        "        temp_image = create_blurred_wrapped_text_image(font, question, quiz_data['background_image'])\n",
        "        question_clip = ImageClip(temp_image).set_duration(5)\n",
        "        question_audio = generate_xttsv2(question, model, gpt_cond_latent, speaker_embedding)\n",
        "        question_clip = question_clip.set_audio(question_audio)\n",
        "        clips.append(question_clip)\n",
        "\n",
        "        temp_image_2 = create_blurred_wrapped_text_image(font, answer, quiz_data['background_image'])\n",
        "        answer_clip = ImageClip(temp_image_2).set_duration(2)\n",
        "        answer_audio = generate_xttsv2(answer, model, gpt_cond_latent, speaker_embedding)\n",
        "        answer_clip = answer_clip.set_audio(answer_audio)\n",
        "        clips.append(answer_clip)\n",
        "\n",
        "    final_clip = concatenate_videoclips(clips)\n",
        "    final_clip = final_clip.set_audio(CompositeAudioClip([final_clip.audio, music_clip]))\n",
        "    final_clip = final_clip.subclip(0, 35)\n",
        "    final_clip.write_videofile(output_file, fps=24)\n",
        "\n",
        "    if os.path.exists(\"tts_audio.mp3\"):\n",
        "        os.remove(\"tts_audio.mp3\")\n",
        "\n",
        "# Main script\n",
        "if __name__ == \"__main__\":\n",
        "    quiz_data = load_quiz('/content/quiz.json')\n",
        "    os.makedirs(\"/content/output\", exist_ok=True)\n",
        "\n",
        "    for quiz in quiz_data['quizzes']:\n",
        "        current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        output_filename = f\"/content/output/quiz_{quiz_data['theme']}_{current_time}.mp4\"\n",
        "        create_quiz_video(quiz, quiz_data, output_filename, model, gpt_cond_latent, speaker_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VdkkWiIbmDe2",
        "outputId": "ad9a942c-a566-41cf-df0e-81a8b6fff66e"
      },
      "outputs": [],
      "source": [
        "import moviepy.editor\n",
        "moviepy.editor.ipython_display(\"/content/output/quiz_harry_potter_20241008_143308.mp4\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
